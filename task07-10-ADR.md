# ADR-007: Проектирование схем и стратегия шардирования MongoDB для «Мобильный мир»

**Дата**: 2025-11-18

## Цель
Спроектировать коллекции products, orders, carts так, чтобы:
- обеспечить быстрые записи заказов с одновременным списанием остатков;
- обеспечить быстрый поиск истории заказов пользователя;
- минимизировать cross-shard fan-out и hot-spots

## Схемы коллекций

### 1) products (каталог товаров)
#### Схема
```
 {
   "_id": ObjectId("..."),          // уникальный ижентификатор товара
   "name": "string",                // наименование товара
   "category": "string",            // категория товаров
   "price": 199.90,                 // цена
   "attributes": { "color": "...", "size":"..." }, // доп атрибуты
   "created_at": ISODate(...),
   "updated_at": ISODate(...)
   }
```

#### Шард-ключ:
```
{ category: "hashed" }
```

#### Обоснование:
- запросы пользовательского каталога обычно фильтруются по категориям товаров и ценам, 
- интернет-магазин сильно вырос, значит количество категория товаров скорее всего измеряется сотнями или даже тысячами, следовательно использование ключа шардирования по категории наиболее эффективно для равномерного распределения данных,
- хэширование по категории товаров распределит горячие категории по шардам, уменьшит hot-spot, 
- хранение остатков выносится в ```inventory``` для уменьшения влияния большого количества операций продаж на каталог товаров (это критично для уменьшения операций перезаписи товаров из каталога, а также упростит кэширование товаров при необходимости).

### 2) inventory (остатки товаров)
#### Схема
```
{
  "_id": ObjectId("..."),
  "product_id": ObjectId("..."),
  "geo_zone": "Москва",
  "qty": 123,                   // актуальный остаток
  "updated_at": ISODate(...)
}
```

#### Шард-ключ:
```
{ product_id: "hashed" }
```

#### Обоснование:
Вынос данных об остатках в отдельную коллекцию позволит:
- делать быстрый поиск и обновление остатка товара, 
- шардировать по ```product_id``` для равномерного распределения данных по шардам, 
- минимизировать влияние на каталог товаров частыми обновлениями данных во время продаж.

### 3) orders (заказы)
#### Схема
```
 {
  "_id": ObjectId("..."),        // order_id
  "customer_id": "user-123",     // идентификатор покупателя
  "order_datetime": ISODate(...),
  "items": [
    { "product_id": ObjectId("..."), "price": 123.0, "qty": 2, "geo_zone": "Москва" }
  ],
  "status": "created|paid|shipped|cancelled",
  "total_amount": 246.0,
  "geo_zone": "Москва",
  "created_at": ISODate(...),
  "updated_at": ISODate(...)
}
```

#### Шард-ключ:
```
{ customer_id: "hashed" }
```

#### Обоснование:
Основной профиль запросов - список заказов конкретного покупателя, поэтому ключ шардирования по его id

### 4) carts (корзины)
#### Схема
```
 {
  "_id": ObjectId("..."),
  "user_id": "user-123",         // null для чисто гостевых — см. effective_user
  "session_id": "sess-abc",      // для гостей
  "effective_user": "user-123"   // user_id (авторизованный клиент) || session_id (если неавторизованный пользователь)
  "items": [{ "product_id": ObjectId("..."), "quantity": 2 }],
  "status": "active|ordered|abandoned",
  "created_at": ISODate(...),
  "updated_at": ISODate(...),
  "expires_at": ISODate(...)     
}
```

#### Шард-ключ:
```
{ effective_user: "hashed" }
```

#### Обоснование:
- значение ```effective_user``` позволяет быстро находить корзину без fan-out, 
- шардирование по ```effective_user:hashed``` равномерно распределит корзины.
- ```status``` меняется со временем, поэтому его нельзя использовать в качестве ключа шардирования

## Команды MongoDB — примеры

### Включаем шардирование БД:

```sh.enableSharding("mobile_world");```


### Шардируем products по category (hashed):

```sh.shardCollection("mobile_world.products", { category: "hashed" });```


### Шардируем inventory по product_id (hashed):

```sh.shardCollection("mobile_world.inventory", { product_id: "hashed" });```


### Шардируем orders по customer_id (hashed):

```sh.shardCollection("mobile_world.orders", { customer_id: "hashed" });```


### Шардируем carts по effective_user (hashed):

```sh.shardCollection("mobile_world.carts", { effective_user: "hashed" });```

### Получение истории заказов клиента

```db.orders.find({ customer_id: "user-123" }).sort({ order_datetime: -1 }).limit(50);```

### Получение корзины гостя
```db.carts.findOne({ effective_user: "sess-id", status: "active" });```


# ADR-008: Выявление и устранение перегруженных шардов в MongoDB

**Дата**: 2025-11-18

## Какую проблему решаем

В коллекции ```products``` используется шард-ключ по категории.

Категория "Электроника" стала самой популярной, из-за чего один шард получил непропорционально большую долю данных и нагрузку.

### Это привело к:
- замедлению запросов по категории "Электроника";
- высокому CPU и IO на одном сервере;
- резкому росту времени отклика;
- увеличению нагрузки на сетевой слой.

### Необходимо:
- создать набор метрик для отслеживания состояния шардов и наличие перекоса в количестве данных,
- создать механизмы автоматического перераспределения данных,
- включить мониторинг, чтобы такие ситуации больше не возникали внезапно.

## Цели решения
- равномерное распределение данных между шард-узлами,
- возможность быстро обнаружить дисбаланс данных на шардах,
- возможность перераспределить данные без остановки системы,
- минимизация риска ситуации, когда популярная категория превращает шард в "бутылочное горлышко".

## Метрики для выявления перегрузок
### Метрики нагрузки на каждый шард
#### CPU и память
- system.cpu.usage
- system.memory.used_percent

Сигнал: один шард стабильно держится ≥ 70–80% CPU, остальные — нет.

#### Диск и IO
- disk.io.read/write
- disk.latency

Сигнал: операции чтения/записи на одном шарде растут быстрее других.

#### Размер данных и количество чанков
- db.chunks.count
- db.chunks.size
- sh.status() — сравнение количества чанков на каждом шарде.

Сигнал: один шард имеет заметно больше чанков (например, > 40% всех чанков кластера).

### Метрики поведения запросов
#### Время отклика запросов, попадающих на конкретный шард
- oplog.query_time_ms
- slow_query_count

Сигнал: медленные запросы появляются только на одном шарде.

#### Количество запросов, приходящих на каждый шард
- cluster.shard_query_count

Сигнал: шард "Электроника" получает непропорционально больше запросов.

#### Метрики состояния балансировщика
Balancer queue

- config.locks
- balancer.active
- balancer.queue_size

Сигнал: балансировщик включён, но не успевает переносить чанки.

## Причины разбалансировки данных

В данном кейсе перегрузка возникла из-за неправильного шард-ключа:
- категорий мало,
- категория "Электроника" содержит много товаров,
- популярная категория оказалась полностью на одном шарде.

## Механизмы устранения перегруженных шардов
### Включение и корректная настройка автоматического балансировщика

MongoDB умеет перераспределять чанки сама.
Убедиться, что балансировщик включён:
```
sh.getBalancerState()
sh.setBalancerState(true)
```

Увеличить размер чанка (или наоборот уменьшить — зависит от нагрузки). Оптимально:
```
use config
db.settings.save({ _id: "chunksize", value: 64 }) // МБ
```

### Принудительное перераспределение данных

В случае явной перегрузки:
```
sh.moveChunk(
"mobile_world.products",
{ category: "Электроника" },
"shard02"
)
```

или сразу:
```
sh.rebalanceCollection("mobile_world.products")
```

### Изменение шард-ключа, если текущий принципиально неправильный

Для products один из эффективных вариантов:
```
{ category: "hashed" }
```

Если, например, сейчас используется range по категории, то это и создаёт проблему.

Делаем полную миграция шард-ключа:
```
sh.startReshardCollection(
"mobile_world.products",
{ category: "hashed" }
)
```
### Использование композитных шард-ключей

Если магазин сильно растёт, и одной категории становится мало, используем такой вариант ключа:
```
{ category: "hashed", price: 1 }
```

для большей кардинальности:
```
{ category: "hashed", _id: 1 }
```

Это дополнительно "размазывает" данные по узлам.

### Ограничение количества запросов к перегруженному шарду

Для резкого снижения нагрузки:
- включение rate-limit на API для товаров из категории "Электроника",
- кэширование каталога категории в Redis,
- вынесение популярных категорий в отдельный read-replica кластер (catalog-service).

## Мониторинг

Используем Prometheus + Grafana.

Дашборды должны показывать по каждому шарду:
- загрузка CPU,
- загрузка RAM,
- IO и задержки,
- количество чанков на шарде,
- скорость перемещения чанков,
- разница в размере коллекций между шардами (больше 20% отличия -> разбалансировка),
- p95/p99 времени запросов, попавших на каждый шард,
- количество медленных запросов,
- размер и состояние очереди балансировщика.

Алерты (сигналы на обнаружения горячих шардов):
- CPU >80% на протяжении 5 минут,
- число чанков у одного шарда > 40% от общего,
- p95 запросов конкретной коллекции ≠ p95 других шардов (разрыв > 30%),
- балансировщик включён, но очередь > 10 чанков,
- один шард обрабатывает > 60% запросов коллекции.

## Автоматизация обнаружения горячих шардов
Алгоритм:
- Обнаружили, что один шард перегружен (проверка тех же условий, что на алертах),
- Балансировщик включён → проверяем, переносит ли он чанки,
- Если нет — запускаем принудительное перераспределение,
- Сообщаем кожаным результат операции.

Если перегрузка повторяется, делаем вручную:
- меняем шард-ключ на hashed,
- дополнительно: включаем кэширование популярных категорий,
- Если проблема в росте категории — композитный ключ.



# ADR-009: Настройка чтения с реплик и консистентность данных

**Дата:** 2025-11-19

---

## 1. Контекст

В кластере MongoDB используются реплика-сеты (primary + несколько secondary).  
Необходимо определить:

- какие операции чтения можно выполнять со secondary,
- какие операции требуют чтения только с primary,
- допустимую задержку репликации для secondary,
- обоснование выбора с точки зрения консистентности, частоты обновлений и бизнес-логики.

---

## 2. Основная логика принятия решений

### Когда **можно читать с secondary**:
- данные обновляются редко,
- небольшая задержка некритична,
- важна разгрузка primary.

### Когда **обязательно читать с primary**:
- данные должны быть строго актуальными "здесь и сейчас",
- устаревшая информация вызывает бизнес-ошибки (продажа отсутствующего товара, неправильный статус заказа, потерянные товары в корзине),
- коллекция активно обновляется.

---

## 3. Таблица: какие чтения куда идут

---

## 3.1. `products`

| Операция | Описание | Куда читать | Обоснование |
|----------|----------|-------------|-------------|
| Получение каталога товаров | список товаров, фильтры | **secondary** | данные не критичны к задержке, обновления относительно редкие |
| Просмотр карточки товара | описание, характеристики | **secondary** | можно отдавать слегка устаревшие данные |
| Проверка остатков при оформлении заказа | доступность товара | **primary** | риск продать товар, которого уже нет |
| Отображение остатка в карточке товара | "в наличии Х штук" | **primary** | ошибочное отображение вводит пользователя в заблуждение |

### Итог по products:
- каталог и карточки → secondary
- остатки → только primary

---

## 3.2. `orders`

| Операция | Куда читать | Обоснование |
|----------|-------------|-------------|
| История заказов | **secondary** | задержка безопасна, данные меняются редко |
| Детали старого заказа | **secondary** | заказ уже не меняется |
| Статус активного заказа | **primary** | статус критичен, должен быть актуальным |
| Проверка состояния заказа при оплате | **primary** | ошибки приведут к сбоям в оплате |
| Трек-номер, логистика | **secondary** | задержка в несколько секунд допустима |

### Итог по orders:
- старые заказы → secondary
- текущие статусы → primary

---

## 3.3. `carts`

| Операция | Куда читать | Обоснование |
|----------|-------------|-------------|
| Получение активной корзины | **primary** | корзина обновляется постоянно, нужна точность |
| Получение корзины гостя по session_id | **primary** | риск увидеть устаревшие данные |
| Слияние корзин (guest → user) | **primary** | малейшие расхождения приводят к багам |
| Значок "кол-во товаров в корзине" в UI | **primary** | UX рушится при расхождении |
| Аналитические выборки (abandoned carts, отчёты) | **secondary** | задержка безопасна, высокая нагрузка не нужна |

### Итог по carts:
- рабочие корзины → только primary
- аналитика → secondary

---

## 4. Допустимая задержка репликации

| Коллекция | Допустимая задержка | Обоснование |
|-----------|----------------------|-------------|
| products | **300–500 мс** | каталог может быть слегка устаревшим |
| orders | **1–2 секунды** для старых заказов, **0** для активных | статус заказа должен быть точным |
| carts | **0 секунд** для активных корзин, **до 5 секунд** для аналитики | корзина — самый динамичный объект |

---

## 5. Итоги и выводы

- `products`: каталог и описание — secondary; остатки — primary.
- `orders`: история — secondary; активные статусы и оплата — primary.
- `carts`: вся рабочая корзина — только primary; аналитика — secondary.
- Допустимые задержки:
    - products: ≤ 300–500 мс
    - orders: ≤ 1–2 сек (кроме активных)
    - carts: 0 сек

Это обеспечивает баланс между производительностью, точностью данных и безопасностью бизнес-процессов.


# ADR: Миграция на Cassandra — модель данных, шардирование и стратегии целостности

## Контекст
Во время "чёрной пятницы" интернет-магазин использовал MongoDB с шардированием на основе диапазонов (Range-Based Sharding). При резком увеличении нагрузки (50 000 запросов/сек.) возникла высокая задержка при масштабировании:
При добавлении новых шардов MongoDB полностью перераспределяла данные между всеми узлами, что вызывало просадку latency в пик нагрузки, так как система тратила ресурсы на перемещение данных.

Нужно перейти на Cassandra, где:
- нет лидеров → нет узкого места;
- добавление нод не вызывает массовое перемещение всех данных;
- кольцевое распределение (consistent hashing) даёт равномерную загрузку;
- система рассчитана на write-heavy нагрузки и геораспределённость.

---

# Задание 10.1 — Какие данные критичны и зачем им Cassandra

## Критически важные данные интернет-магазина
| Сущность | Критичность | Почему важна |
|---------|-------------|--------------|
| **Orders (заказы)** | крайне высокая | огромный объём записи, важна доступность, но полная строгая консистентность не всегда нужна. |
| **Order History (история заказов)** | высокая | write-heavy, растёт бесконечно, удобна под time-series модель. |
| **Carts (корзины)** | средняя | много конкурентных изменений, но потеря корзины не критична. |
| **Product Views / Events (просмотры, клики)** | низкая | нужен быстрый ingest, eventual consistency ок. |
| **User Sessions** | высокая | запись/чтение — миллионы раз, нет смысла держать в Mongo. |
| **Products (товары)** | средняя | изменяются редко, читаются часто. Cassandra подходит, но не обязательно. |

## Где Cassandra действительно оправдана
Выбираем сущности, которые:
- получают **много записей** (write-heavy),
- должны выдерживать **очень высокую нагрузку**,
- могут жить с eventual consistency,
- должны легко масштабироваться,
- не должны разваливаться при решардинге.

### Сущности, которые точно переносим в Cassandra:
1. **Заказы (orders)** — write-heavy, огромные объёмы, важна доступность.
2. **История заказов (order_events/time-series)** — идеальный кейс под Cassandra.
3. **Сессии пользователей** — миллионы операций, TTL, быстрая запись.
4. **Корзины (carts)** — частые изменения, можно мириться с eventual consistency.

### Что НЕ нужно переносить:
- **Products (каталог)** — мало обновляется, логичнее оставить в Mongo/Postgres/Elastic, так как нужна строгая консистентность и сложные фильтры.

---

# Задание 10.2 — Модель данных + partition/cluster keys

Ниже — концептуальная модель под Cassandra, оптимизированная под перегрев партиций и распределение нагрузки.

---

## **1. Таблица orders**
### Модель запросов
- Получить заказ по order_id.
- Получить все заказы пользователя.

### Primary Key
```PRIMARY KEY ((user_id), order_id)```

### Обоснование:
- `user_id` равномерно распределяет заказы по кольцу → нет горячих партиций.
- `order_id` как clustering key — позволяет сортировать заказы (например, по времени).

```sql
CREATE TABLE orders (
    user_id UUID,
    order_id UUID,
    created_at timestamp,
    status text,
    total decimal,
    items list<frozen<item>>,
    PRIMARY KEY ((user_id), order_id)
) WITH CLUSTERING ORDER BY (order_id DESC);
```

---

## **2. Таблица order_events (история заказов, time-series)**
### Модель запросов
- Быстро вытянуть историю для одного заказа.

### Primary Key
```PRIMARY KEY ((order_id), event_ts)```

### Обоснование:
- Все события одного заказа идут в одну партицию — быстро, компактно.
- Диапазон по времени читается эффективно.

```sql
CREATE TABLE order_events (
order_id UUID,
event_ts timestamp,
event_type text,
payload text,
PRIMARY KEY ((order_id), event_ts)
) WITH CLUSTERING ORDER BY (event_ts ASC);
```

## **3. Таблица carts**
### Модель запросов
- Получить корзину по user_id.
- Частое обновление, много одновременных операций.

### Primary Key
```PRIMARY KEY ((user_id))```

### Обоснование:
- Одна корзина = один пользователь → одна партиция.
- Нагрузка распределяется по user_id → нет "точек перегрева".

```sql
CREATE TABLE carts (
user_id UUID,
items map<text,int>,
updated_at timestamp,
PRIMARY KEY ((user_id))
);
```

## **4. Таблица user_sessions**
### Модель запросов
- Прочитать/обновить сессию.
- Сессионные данные живут до TTL.

### Primary Key
```PRIMARY KEY ((session_id))```

### Обоснование:
- Одна запись = одна партиция.
- Абсолютно равномерное распределение по session_id.

```sql
CREATE TABLE user_sessions (
session_id UUID,
user_id UUID,
created_at timestamp,
expires_at timestamp,
data text,
PRIMARY KEY ((session_id))
) WITH default_time_to_live = 86400;
```

## Обоснование выбора моделей
### Как предотвращаем горячие партиции:
- Используем значения, которые хорошо хешируются (UUID, user_id).
- Исключаем диапазоны времени как partition key (иначе один день превратился бы в hot partition).
- Каждая запись падает почти равномерно по кольцу.

### Как минимизируем влияние решардинга:
- Cassandra не делает глобальной перестановки — только часть токенов переезжает.
- При добавлении ноды нагрузка автоматически перераспределяется равномерно.
- Модель избегает огромных партиций → миграция токенов быстрая.

---

# Задание 10.3 — Стратегии целостности данных: что и где применять
| Стратегия               | Что делает                                                                 | Где применяется                                                          |
| ----------------------- | -------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| **Hinted Handoff**      | временно хранит недоставленные записи и догружает на восстановившийся узел | carts, sessions, order_events — подходит для eventual consistency        |
| **Read Repair**         | исправляет расхождения во время чтения                                     | orders, order_events — важно, чтобы пользователь видел актуальные данные |
| **Anti-Entropy Repair** | периодически сравнивает и синхронизирует ноды                              | orders, carts — долгосрочная согласованность                             |

## Рекомендации по сущностям
### 1. Orders
- Read Repair: включить
- Anti-Entropy Repair: периодический
- Hinted Handoff: включить

Почему: критичные данные, но нагрузка огромная. Нужно eventual consistency + постоянные фоновые синхронизации.

### 2. Order Events (история)
- Hinted Handoff: включить
- Read Repair: опционально
- Anti-Entropy Repair: реже, так как данные иммутабельные

### 3. Carts
- Hinted Handoff: обязательно
- Read Repair: можно выключить — нет смысла чинить корзину "на чтении"
- Anti-Entropy Repair: раз в сутки

### 4. User Sessions
- Hinted Handoff: включить
- Read Repair: не нужен
- Anti-Entropy Repair: почти не нужен — данные живут по TTL

---

# Заключение

Миграция на Cassandra оправдана для write-heavy сущностей: заказы, история заказов, корзины, сессии.
Модель на основе хорошо распределяемых ключей (user_id, order_id, session_id) устраняет горячие партиции и обеспечивает равномерную нагрузку.

Стратегии восстановления:
- Hinted Handoff для доступности.
- Read Repair для критичных данных.
- Anti-Entropy Repair как фоновая долгосрочная синхронизация.

